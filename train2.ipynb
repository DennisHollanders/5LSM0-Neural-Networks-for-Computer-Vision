{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from torchvision.datasets import Cityscapes\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation for input images and masks\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "target_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32), transforms.InterpolationMode.NEAREST),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# load dataset\n",
    "data_path = \"C:/Users/20193625/OneDrive - TU Eindhoven/Documents/5LSM0/5LSM0_Final_Project/CityScapes\"\n",
    "train_dataset = Cityscapes(root=data_path,\n",
    "                     split='train',\n",
    "                     mode='fine',\n",
    "                     target_type='semantic',\n",
    "                     transform=transform,\n",
    "                     target_transform=target_transforms)\n",
    "\n",
    "val_dataset = Cityscapes(root=data_path,\n",
    "                         split='val',\n",
    "                         mode='fine',\n",
    "                         target_type='semantic',\n",
    "                         transform=transform,\n",
    "                         target_transform=target_transforms)\n",
    "\n",
    "\n",
    "# create small subset of dataset\n",
    "torch.manual_seed(1)\n",
    "subset_size = int(0.05 * len(train_dataset))\n",
    "indices = torch.randperm(len(train_dataset))[:subset_size]\n",
    "train_subset = Subset(train_dataset, indices)\n",
    "val_subset = Subset(val_dataset, indices)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_subset, batch_size=8, shuffle=True) # Num workers and Pin Memory??\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(images, targets, n):\n",
    "    fig, axs = plt.subplots(n, 2, figsize=(6, n * 2))\n",
    "\n",
    "    for i in range(n):\n",
    "        image = images[i].permute(1,2,0).numpy()\n",
    "        target = targets[i].squeeze().numpy()\n",
    "\n",
    "        axs[i,0].imshow(image)\n",
    "        axs[i,0].set_title('Image')\n",
    "        axs[i,0].axis('off')\n",
    "\n",
    "        axs[i,1].imshow(target)\n",
    "        axs[i,1].set_title('Segmentation')\n",
    "        axs[i,1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(images, targets, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function (don't forget to ignore class index 255)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=255) # DICE LOSS MAKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/validation loop\n",
    "def train_model_segmentation(model, train_loader, num_epochs=5, lr=0.01):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, masks in train_loader:\n",
    "            masks = (masks*255).long().squeeze()     #*255 because the id are normalized between 0-1\n",
    "            masks = map_id_to_train_id(masks)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            masks = (masks * 255)\n",
    "\n",
    "            loss = loss_function(outputs, masks.long().squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_segmentation(model, train_loader, 20, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "class_names = []\n",
    "for cls in train_dataset.classes:\n",
    "    colors[cls.id]= cls.color\n",
    "    class_names.append(cls.name)\n",
    "\n",
    "print(colors)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rgb(mask, class_to_color):\n",
    "    \"\"\"\n",
    "    Converts a numpy mask with multiple classes indicated by integers to a color RGB mask.\n",
    "\n",
    "    Parameters:\n",
    "        mask (numpy.ndarray): The input mask where each integer represents a class.\n",
    "        class_to_color (dict): A dictionary mapping class integers to RGB color tuples.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: RGB mask where each pixel is represented as an RGB tuple.\n",
    "    \"\"\"\n",
    "    # Get dimensions of the input mask\n",
    "    height, width = mask.shape\n",
    "\n",
    "    # Initialize an empty RGB mask\n",
    "    rgb_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Iterate over each class and assign corresponding RGB color\n",
    "    for class_idx, color in class_to_color.items():\n",
    "        # Mask pixels belonging to the current class\n",
    "        class_pixels = mask == class_idx\n",
    "        # Assign RGB color to the corresponding pixels\n",
    "        rgb_mask[class_pixels] = color\n",
    "\n",
    "    return rgb_mask\n",
    "\n",
    "def visualize_segmentation(model, dataloader, num_examples=5):\n",
    "    \"\"\"\n",
    "    Visualizes segmentation results from a given model using a dataloader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The segmentation model to visualize.\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader providing image-mask pairs.\n",
    "        num_examples (int, optional): Number of examples to visualize. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(dataloader):\n",
    "            if i >= num_examples:\n",
    "                break\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = torch.softmax(outputs, dim=1)\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "            images = images.numpy()\n",
    "            masks = masks.numpy()*255\n",
    "\n",
    "            predicted = predicted.numpy()\n",
    "\n",
    "            for j in range(images.shape[0]):\n",
    "                image = renormalize_image(images[j].transpose(1, 2, 0))\n",
    "\n",
    "                mask = masks[j].squeeze()\n",
    "                pred_mask = predicted[j]\n",
    "                                \n",
    "                # Convert mask and predicted mask to RGB for visualization\n",
    "                mask_rgb = mask_to_rgb(mask, colors)\n",
    "                pred_mask_rgb = mask_to_rgb(pred_mask, colors)\n",
    "                \n",
    "                # Get unique classes present in the ground truth and predicted masks\n",
    "                unique_classes_gt = np.unique(mask)\n",
    "                unique_classes_pred = np.unique(pred_mask)\n",
    "                \n",
    "                unique_classes_gt = np.delete(unique_classes_gt, [0, -1])\n",
    "                unique_classes_pred= np.delete(unique_classes_pred, 0)\n",
    "                \n",
    "                unique_classes_gt[unique_classes_gt == 255] = 0\n",
    "                unique_classes_pred[unique_classes_pred == 255] = 0\n",
    "                \n",
    "                # Map class indices to class names from the VOC2012 dataset\n",
    "                classes_gt = [class_names[int(idx)] for idx in unique_classes_gt]\n",
    "                classes_pred = [class_names[int(idx)] for idx in unique_classes_pred]\n",
    "                \n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(image)\n",
    "                plt.title('Image')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(mask_rgb)\n",
    "                # plt.title(f'Ground Truth Mask Classes:\\n {classes_gt}')\n",
    "                plt.title(f'Ground Truth Mask Classes:')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(pred_mask_rgb)\n",
    "                # plt.title(f'Predicted Mask Predicted Classes:\\n {classes_pred}')\n",
    "                plt.title(f'Predicted Mask Predicted Classes:')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.show()\n",
    "                \n",
    "\n",
    "def renormalize_image(image):\n",
    "    \"\"\"\n",
    "    Renormalizes the image to its original range.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Image tensor to renormalize.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Renormalized image tensor.\n",
    "    \"\"\"\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]  \n",
    "    renormalized_image = image * std + mean\n",
    "    return renormalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_segmentation(model, val_loader, num_examples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
